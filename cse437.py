# -*- coding: utf-8 -*-
"""CSE437

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rBtCYAjm3U0qEjtNf4sBP7y9qldg0elt
"""

# Import Libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import plotly.express as px

# Libraries for Sentiment Analysis
import re
import nltk
from nltk.corpus import stopwords
from nltk.corpus import wordnet
from nltk.stem import WordNetLemmatizer
from textblob import TextBlob
from wordcloud import WordCloud

# to avoid warnings
import warnings
warnings.filterwarnings('ignore')

# reading datasets
trump = pd.read_csv("hashtag_donaldtrump.csv", lineterminator='\n')
print(trump.head(3))

# Display all the columns in the DataFrame
print(trump.columns)


print(trump.shape)

# Getting trump dataset information
trump.info()

trump['candidate'] = 'trump'

data = pd.concat([trump])

print('Final Data Shape :', data.shape)

# View the first 2 rows
print("\nFirst 2 rows:")
print(data.head(3))

data.dropna(inplace=True)

data['country'].value_counts()

data['country'] = data['country'].replace({'United States of America': "US",'United States': "US"})

# Top10 Countrywise tweets Counts
top10countries = data.groupby('country')['tweet'].count(
).sort_values(ascending=False).reset_index().head(10)
# top10countries

# Interactive bar chart
fig = px.bar(top10countries, x='country', y='tweet',
template='plotly_dark',
color_discrete_sequence=px.colors.qualitative.Dark24_r,
title='Top10 Countrywise tweets Counts')

# To view the graph
fig.show()

trump_tweets = data[data['candidate'] == 'trump']

# taking only U.S. country data
trump_tweets = trump_tweets.loc[trump_tweets.country == 'US']
trump_tweets = trump_tweets[['tweet']]
print(trump_tweets.head())

def clean(text):
	# Remove URLs
	text = re.sub(r'https?://\S+|www\.\S+', '', str(text))

	# Convert text to lowercase
	text = text.lower()

	# Replace anything other than alphabets a-z with a space
	text = re.sub('[^a-z]', ' ', text)

	# Split the text into single words
	text = text.split()

	# Initialize WordNetLemmatizer
	lm = WordNetLemmatizer()

	# Lemmatize words and remove stopwords
	text = [lm.lemmatize(word) for word in text if word not in set(
		stopwords.words('english'))]

	# Join the words back into a sentence
	text = ' '.join(word for word in text)

	return text

def getpolarity(text):
    return TextBlob(text).sentiment.polarity

def getsubjectivity(text):
    return TextBlob(text).sentiment.subjectivity

def getAnalysis(score):
    if score < 0:
        return 'negative'
    elif score == 0:
        return 'neutral'
    else:
        return 'positive'

trump_tweets['cleantext'] = trump_tweets['tweet'].apply(clean)
print(trump_tweets.head())

trump_tweets['subjectivity'] = trump_tweets['cleantext'].apply(getsubjectivity)

trump_tweets['polarity'] = trump_tweets['cleantext'].apply(getpolarity)

trump_tweets['analysis'] = trump_tweets['polarity'].apply(getAnalysis)
trump_tweets.head()

# how much data is positive/negetive/neutral
plt.style.use('dark_background') # Adding black theme

# Define colors for each bar
colors = ['orange', 'blue', 'red']

plt.figure(figsize=(7, 5))
(trump_tweets.analysis.value_counts(normalize=True) * 100).plot.bar(color=colors)
plt.ylabel("%age of tweets")
plt.title("Distribution of Sentiments towards Trump")
plt.show()

from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator

def word_cloud(wd_list):
	stopwords = set(STOPWORDS)
	all_words = ' '.join([text for text in wd_list])
	wordcloud = WordCloud(background_color='black',
						stopwords=stopwords,
						width=1600, height=800, max_words=100, max_font_size=200,
						colormap="viridis").generate(all_words)
	plt.figure(figsize=(12, 10))
	plt.axis('off')
	plt.imshow(wordcloud)

word_cloud(trump_tweets['cleantext'][:5000])

trump_tweets.analysis.value_counts(normalize=True)*100







import math
from scipy.stats import norm

def z_test_for_proportions(x1, n1, x2, n2):
    # Proportions
    p1 = x1 / n1
    p2 = x2 / n2

    # Pooled proportion
    p = (x1 + x2) / (n1 + n2)

    # Standard error
    se = math.sqrt(p * (1 - p) * (1/n1 + 1/n2))

    # Z-score
    z = (p1 - p2) / se

    # P-value (two-tailed)
    p_value = 2 * (1 - norm.cdf(abs(z)))

    return z, p_value

# Example input
x1 = 50  # Negative tweets in group 1
n1 = 200  # Total tweets in group 1
x2 = 30  # Negative tweets in group 2
n2 = 150  # Total tweets in group 2

z, p_value = z_test_for_proportions(x1, n1, x2, n2)
print(f"Z-score: {z}")
print(f"P-value: {p_value}")